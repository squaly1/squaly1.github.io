<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>github图床别用cdn</title>
      <link href="/post/10899.html"/>
      <url>/post/10899.html</url>
      
        <content type="html"><![CDATA[<p>picGo搭建github图床遇坑，图片经常显示不了。</p><p>网上好多教程搭建github图床使用cdn加速，实测cdn经常抽风，墙的问题，这样还不如不用cdn加速。</p><p>直接用<a href="https://raw.githubusercontent.com/[username/]/[%E4%BB%93%E5%BA%93%E5%90%8D]">https://raw.githubusercontent.com/[username\]/[仓库名]</a></p><p>别用这种形式：<red> <a href="https://cdn.jsdelivr.net/gh/[github%E7%94%A8%E6%88%B7%E5%90%8D]/[%E4%BB%93%E5%BA%93%E5%90%8D]@main">https://cdn.jsdelivr.net/gh/[github用户名]/[仓库名]@main</a> </red></p><p>最好自己搭建兰空图床吧，反正自己有nas了</p>]]></content>
      
      
      
        <tags>
            
            <tag> github </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>实战ubuntu代替群晖做nas(1)</title>
      <link href="/post/10084.html"/>
      <url>/post/10084.html</url>
      
        <content type="html"><![CDATA[<h1 id="引言：为什么不用群晖？"><a href="#引言：为什么不用群晖？" class="headerlink" title="引言：为什么不用群晖？"></a>引言：为什么不用群晖？</h1><h3>.作为一个家庭服务系统，最主要的是：</h3><p>1.稳定</p><p>2.故障恢复容易</p><p>3.硬件兼容性好</p><p>4.软件扩展性强</p><p>群晖很明显不具备以上几点，但这却是ubuntu的强项，linxu的开源，稳定性兼容无容置疑，唯一的缺点是使用习惯的问题而已，其实群晖的ui操作的逻辑并不好，docker的ui设置逻辑经常变换，web station更不用说，简直是噩梦，正确设置完也不明白软件的运行原理，黑群引导升级各种痛苦（现在有aprl引导算简单了，大版本更新后仍是麻烦），硬件各种不兼容，数据恢复各种失败，经过10几年的黑群折磨后决心转向ubuntu。</p><h2 id="操作步骤"><a href="#操作步骤" class="headerlink" title=".操作步骤"></a>.操作步骤</h2><p>2023年没人不用虚拟机了，esxi操作简单，稳定，一直是host系统首选。</p><h3 id="1-直通m2硬盘"><a href="#1-直通m2硬盘" class="headerlink" title="1.直通m2硬盘"></a>1.直通m2硬盘</h3><p>可以用多条做阵列，up主用了两条，组raid0，用来pt挂种子</p><p><img src="https://app.bliyun.me:9080/i/2023/11/10/654d5631e16ac.jpg" alt="虚拟机设置"></p><h3 id="2-安装系统"><a href="#2-安装系统" class="headerlink" title="2.安装系统"></a>2.安装系统</h3><p>请参考网上其他教程</p><h3 id="3-磁盘设置"><a href="#3-磁盘设置" class="headerlink" title="3.磁盘设置"></a>3.磁盘设置</h3><p>首先要su权限</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo passwd root  # 设置root密码</span><br><span class="line">sudo su #切换root用户</span><br></pre></td></tr></table></figure><p>安装阵列</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install mdadm #root权限安装阵列软件</span><br><span class="line">sudo lsblk #查看可用磁盘</span><br></pre></td></tr></table></figure><p>运行结果（下面结果中的sdb和sdc两个磁盘是我们准备创建RAID 0的两块盘）：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">NAME                MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT</span><br><span class="line">sda                   8:0    0   60G  0 disk </span><br><span class="line">├─sda1                8:1    0  512M  0 part /boot/efi</span><br><span class="line">├─sda2                8:2    0    1K  0 part </span><br><span class="line">└─sda5                8:5    0 59.5G  0 part </span><br><span class="line">  ├─vgubuntu-root   253:0    0 58.6G  0 lvm  /</span><br><span class="line">  └─vgubuntu-swap_1 253:1    0  980M  0 lvm  [SWAP]</span><br><span class="line">sdb                   8:16   0   30G  0 disk </span><br><span class="line">sdc                   8:32   0   30G  0 disk </span><br><span class="line">sr0                  11:0    1 1024M  0 rom  </span><br></pre></td></tr></table></figure><p>创建RAID</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">root@ubuntu:~$ sudo mdadm --create --verbose /dev/md0 --level=0 --raid-devices=2 /dev/sdb /dev/sdc</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>运行结果</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mdadm: chunk size defaults to 512K</span><br><span class="line">mdadm: Defaulting to version 1.2 metadata</span><br><span class="line">mdadm: array /dev/md0 started.</span><br></pre></td></tr></table></figure><p>查看创建结果</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat /proc/mdstat</span><br></pre></td></tr></table></figure><p>运行结果</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Personalities : [linear] [multipath] [raid0] [raid1] [raid6] [raid5] [raid4] [raid10] </span><br><span class="line">md0 : active raid0 sdc[1] sdb[0]</span><br><span class="line">      62879744 blocks super 1.2 512k chunks</span><br><span class="line">      </span><br><span class="line">unused devices: &lt;none&gt;</span><br></pre></td></tr></table></figure><p>从上面的输出结果中可以看到md0已经创建成功。</p><p>格式化RAID</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo mkfs.ext4 /dev/md0</span><br></pre></td></tr></table></figure><p>运行结果</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">mke2fs 1.45.5 (07-Jan-2020)</span><br><span class="line">创建含有 15719936 个块（每块 4k）和 3932160 个inode的文件系统</span><br><span class="line">文件系统UUID：1aaeec0c-d918-4e91-802e-f8f2e9645b56</span><br><span class="line">超级块的备份存储于下列块： </span><br><span class="line">32768, 98304, 163840, 229376, 294912, 819200, 884736, 1605632, 2654208, </span><br><span class="line">4096000, 7962624, 11239424</span><br><span class="line"></span><br><span class="line">正在分配组表： 完成                            </span><br><span class="line">正在写入inode表： 完成                            </span><br><span class="line">创建日志（65536 个块） 完成</span><br><span class="line">写入超级块和文件系统账户统计信息： 已完成 </span><br></pre></td></tr></table></figure><p>挂载RAID,手动挂载命令如下（手动挂载重启后会失效，下文会介绍如何设置开机自动挂载）：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cd /mnt                     # 切换到/mnt路径</span><br><span class="line">sudo mkdir raid0            # mnt为root权限，因此需要使用sudo来创建</span><br><span class="line">sudo mount /dev/md0 raid0/</span><br><span class="line">sudo chown -R squaly:squaly raid0  # 为方便使用可将目录改为当前用户权限</span><br></pre></td></tr></table></figure><p>查看当前文件系统</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df -h</span><br></pre></td></tr></table></figure><p>运行结果</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">文件系统                   容量  已用  可用 已用% 挂载点</span><br><span class="line">udev                       5.9G     0  5.9G    0% /dev</span><br><span class="line">tmpfs                      1.2G  3.2M  1.2G    1% /run</span><br><span class="line">/dev/mapper/vgubuntu-root   58G   18G   38G   32% /</span><br><span class="line">tmpfs                      5.9G   46M  5.8G    1% /dev/shm</span><br><span class="line">tmpfs                      5.0M  4.0K  5.0M    1% /run/lock</span><br><span class="line">tmpfs                      5.9G     0  5.9G    0% /sys/fs/cgroup</span><br><span class="line">/dev/sda1                  511M  4.0K  511M    1% /boot/efi</span><br><span class="line">tmpfs                      1.2G   92K  1.2G    1% /run/user/1000</span><br><span class="line">/dev/md0                    59G   53M   56G    1% /mnt/raid0</span><br></pre></td></tr></table></figure><p>从上面结果的最后一行可以看到我们创建的 md0 已经被挂载到了 &#x2F;mnt&#x2F;raid0 ，其空间大小为原始的两块磁盘的2倍。</p><p>开机自动挂载RAID</p><p>查询 md0 设备的UUID，命令如下:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo blkid /dev/md0</span><br></pre></td></tr></table></figure><p>运行结果：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/dev/md0: UUID=&quot;1aaeec0c-d918-4e91-802e-f8f2e9645b56&quot; TYPE=&quot;ext4&quot;</span><br></pre></td></tr></table></figure><p>上面的结果中的UUID后面的字符串即为我们要获取的内容，然后通过 vim 打开配置文件：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/fstab</span><br></pre></td></tr></table></figure><p>具体配置如下，将下面这行添加到打开的文件末尾即可：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">UUID=1aaeec0c-d918-4e91-802e-f8f2e9645b56 /mnt/raid0 ext4 defaults 0 0</span><br></pre></td></tr></table></figure><p>保存RAID信息到配置文件</p><p>完成上述命令后为保证下次重启RAID配置自动生效，还需要将RAID信息保存到配置文件。<br>运行如下命令查看RAID详情：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo update-initramfs -u</span><br><span class="line">sudo mdadm --detail --scan</span><br></pre></td></tr></table></figure><p>运行结果：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ARRAY /dev/md0 metadata=1.2 name=kylin:0 UUID=9692c01a:85861e21:53389a0e:6b4915ad</span><br></pre></td></tr></table></figure><p>参照上面配置fstab文件的方法，使用 vim 打开文件 &#x2F;etc&#x2F;mdadm&#x2F;mdadm.conf ,将上面命令的输出结果添加到文件末尾即可。</p>]]></content>
      
      
      
        <tags>
            
            <tag> ubuntu </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>emby容器推荐amilys/embyserver</title>
      <link href="/post/46998.html"/>
      <url>/post/46998.html</url>
      
        <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>开心版的emby容器有很多，比较出名的是lovechan，zishuo（不推荐，已经3年多没更新了），下面介绍的是amilys，目前使用比较满意，主要推荐原因是集成了几个插件：</p><p>容器地址：</p><p><a href="https://registry.hub.docker.com/r/amilys/embyserver/">https://registry.hub.docker.com/r/amilys/embyserver/</a></p><h2 id="1-增加了主题："><a href="#1-增加了主题：" class="headerlink" title="1:增加了主题："></a>1:增加了主题：</h2><p><a href="https://github.com/Nolovenodie/emby-crxhttps://github.com/Nolovenodie/emby-crx">https://github.com/Nolovenodie/emby-crxhttps://github.com/Nolovenodie/emby-crx</a></p><p><img src="https://app.bliyun.me:9080/i/2023/11/11/654f314f72df3.png" alt="主题"></p><h2 id="2-dd-danmaku-Emby-弹幕库插件（这插件我一直没成功开启过）："><a href="#2-dd-danmaku-Emby-弹幕库插件（这插件我一直没成功开启过）：" class="headerlink" title="2:dd-danmaku Emby 弹幕库插件（这插件我一直没成功开启过）："></a>2:dd-danmaku Emby 弹幕库插件（这插件我一直没成功开启过）：</h2><p><a href="https://github.com/RyoLee/dd-danmaku">https://github.com/RyoLee/dd-danmaku</a></p><p>开启&#x2F;关闭 请在&#x2F;config&#x2F;config&#x2F;ext.sh 中设置</p><p><img src="https://app.bliyun.me:9080/i/2023/11/11/654f3199a81f7.png" alt="S0"></p><h2 id="3：调用外部播放器："><a href="#3：调用外部播放器：" class="headerlink" title="3：调用外部播放器："></a>3：调用外部播放器：</h2><p><a href="https://github.com/bpking1/embyExternalUrl">https://github.com/bpking1/embyExternalUrl</a></p><h3 id="重点推荐"><a href="#重点推荐" class="headerlink" title="重点推荐"></a>重点推荐</h3><p>非常实用的插件，本地播放基本上不需要显卡转码，现在的硬件足够强大了，根本不需要显卡转码，tv播放，up主用<b>shield tv 2019 pro</b>电视上直接源码播放，主要是网页chrome和手机上播放，部分视频没转吗直接播放不了，现在有了这个插件，完美解决了。</p><p>服务端安装后，在浏览器会出现播放器的图标，点击图标就可以调用外部播放器了。 </p><p><img src="https://app.bliyun.me:9080/i/2023/11/09/654c6adc63520.png" alt="emby"></p><p><b>vlc需要修改路径，mac用户推荐使用iina</b></p><h2 id="4-修改了tdmb的dns"><a href="#4-修改了tdmb的dns" class="headerlink" title="4.修改了tdmb的dns"></a>4.修改了tdmb的dns</h2><p>不用魔法上网也可以正常获得源数据</p><h1 id="安装方式：-可选"><a href="#安装方式：-可选" class="headerlink" title="安装方式：(可选)"></a>安装方式：(可选)</h1><h2 id="1-群晖用户"><a href="#1-群晖用户" class="headerlink" title="1.群晖用户"></a>1.群晖用户</h2><p><img src="https://app.bliyun.me:9080/i/2023/11/09/654c6b9dc7be5.png" alt="群晖"></p><h2 id="2-docker-compose安装（推荐）"><a href="#2-docker-compose安装（推荐）" class="headerlink" title="2.docker-compose安装（推荐）"></a>2.docker-compose安装（推荐）</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">version: &#x27;3.5&#x27;</span><br><span class="line">services:</span><br><span class="line">    emby:</span><br><span class="line">      image: amilys/embyserver:latest</span><br><span class="line">      container_name: emby</span><br><span class="line">      network_mode: bridge</span><br><span class="line">      volumes:</span><br><span class="line">        - ./config:/config</span><br><span class="line">        - ./cache:/cache</span><br><span class="line">        - /mnt:/mnt</span><br><span class="line">      ports:</span><br><span class="line">        - &#x27;8096:8096&#x27;</span><br><span class="line">      devices:</span><br><span class="line">        - /dev/dri:/dev/dri</span><br><span class="line">      privileged: true</span><br><span class="line">      environment:</span><br><span class="line">        - UID=0</span><br><span class="line">        - GID=0</span><br><span class="line">        - GIDLIST=0</span><br><span class="line">        - TZ=&quot;Asia/Shanghai&quot;</span><br><span class="line">      extra_hosts:</span><br><span class="line">        - &quot;api.themoviedb.org:143.204.82.126&quot;</span><br><span class="line">        - &quot;image.tmdb.org:99.86.7.63&quot;</span><br><span class="line">        - &quot;themoviedb.org:99.84.130.66&quot;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> emby </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>解决重装emby后播放错误的bug</title>
      <link href="/post/10540.html"/>
      <url>/post/10540.html</url>
      
        <content type="html"><![CDATA[<h3 id="倒霉的孩子，老是遇上奇奇怪怪的问题"><a href="#倒霉的孩子，老是遇上奇奇怪怪的问题" class="headerlink" title="倒霉的孩子，老是遇上奇奇怪怪的问题"></a>倒霉的孩子，老是遇上奇奇怪怪的问题</h3><p>之前为了磁盘阵列的健康，把pt和各种套件放在2t的m2里面，pt做种满了，尝试用另外一条m2，做raid1增加储存空间，结果黑群提示：<b>此硬盘通过适配器卡安装，无法用于M.2 SSD存储池</b>,顿时石化了，之前已经安装过<a href="https://github.com/007revad/Synology_HDD_db">Synology_HDD_db</a>，（这个工具可以修改群晖不识别m2的问题）再操作一次，重启无数次没有效果，</p><p>这个时候估计要到ssh里面用命令新建储存空间了，由于不确定是否可行，万一又无法使用就浪费时间了。以后肯定会再加m2，甚至u2硬盘，以群晖的兼容性这么差，肯定要重做无数同一操作了，索性推到重做吧。</p><p>暂时装个emby暂时用吧，毕竟要看电视。</p><p>好了，这时候遇上bug了，之前docker已经映射了config和vedio目录，理论上重装无数次，只要配置一样，emby里面就不用重覆设置了，特别是元数据，重新扫描一次多费时间，还有用户设置和播放记录，</p><p>但是却一直出现提示：没有兼容的流,折腾了好久，重装了几次容器，最后的解决方法是：在媒体库删掉映射的文件夹再重新添加，遇到一样问题的不用折腾了，让emby重新扫描一次缓存吧。</p><p><img src="https://app.bliyun.me:9080/i/2023/11/14/655339de0acc0.jpg" alt="文件夹"></p>]]></content>
      
      
      
        <tags>
            
            <tag> emby </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>群晖使用truenas储存做储存空间</title>
      <link href="/post/30000.html"/>
      <url>/post/30000.html</url>
      
        <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>玩黑群已经有10年左右了，从n54l就开始折腾，随着时间的增加和硬件的不断更换，渐渐觉得黑群不是一个长久使用的方案，原因是，黑群的版本对硬件限制越来越麻烦，例如：网卡驱动，阵列卡不识别，m2不能做储存空间等，最麻烦的是居然不能支持部分hba卡，（例如：戴尔的h330，除非刷直通模式，但风险极大，容易砖）以上种种问题都有方法解决，如果你要换硬件首先要考虑引导能不能驱动，但在你安装新硬件之前是几乎完全不知道能否驱动成功的。</p><p>第2要考虑的是，群晖的文件系统恢复不是一般的麻烦，在其他系统读取文件很困难，如果文件多恢复到一半出现错误真的一点心情都没有。</p><p>现在主要用的是docker的服务，除了photos其他都有代替方案，photos的客户端方便些。</p><p>truenas作为一个免费的操作系统，升级方便，对硬件支持好，而且zfs有很大的优势，于是用truenas代替群晖的储存功能是一个不错的选择，储存和服务分离是大势所趋，不会因为群晖升级失败或新硬件识别不了等问题导致数据读取不了。</p><p>群晖用来跑服务，但nfs共享文件夹不能放套件和homes文件，于是有了以下方法。</p><h2 id="使用方法"><a href="#使用方法" class="headerlink" title="使用方法"></a>使用方法</h2><h3 id="1-1-nfs设置"><a href="#1-1-nfs设置" class="headerlink" title="1.1 nfs设置"></a>1.1 nfs设置</h3><p>在truenas部署好硬盘和数据集后，开启nfs，并设置好权限，复制数据集地址</p><h3 id="1-2-esxi挂载nfs"><a href="#1-2-esxi挂载nfs" class="headerlink" title="1.2 esxi挂载nfs"></a><img src="https://app.bliyun.me:9080/i/2023/11/14/65533a5fbb73f.jpg" alt="可以直接选择acl的open预设策略，如果遇到权限不够再增加群组权限">1.2 esxi挂载nfs</h3><p>来到esxi填上简单的配置信息</p><p><img src="https://app.bliyun.me:9080/i/2023/11/14/65533a81956a3.jpg" alt="esxi"></p><h3 id="1-3-虚拟机设置"><a href="#1-3-虚拟机设置" class="headerlink" title="1.3 虚拟机设置"></a>1.3 虚拟机设置</h3><p>虚拟机设置增加上truenas的nfs硬盘，容量随意，按照自己的习惯填写，一般上放些文件和相片</p><h1 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h1><p>在群晖新建储存空间就可以正常使用了，群晖识别不出是虚拟硬盘，可以正常的存放套件或做homes目录，这里不建议大家把qbttorrent放到truenas的文件夹，pt会产生大量的碎片，对阵列影响很大，建议用m2做储存空间给群晖pt，保险起见qbttorrent也安装在m2，pt时候会产生缓存文件。</p><p><b>enjoy～！</b></p>]]></content>
      
      
      
        <tags>
            
            <tag> 群晖 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>nastools文件夹同步正确设置</title>
      <link href="/post/31699.html"/>
      <url>/post/31699.html</url>
      
        <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>nastools最烦的是文件夹同步的设置，刚刚开始时被网上的教程看到一头雾水，什么不能分不同硬盘，必须这只link目录等都是误导，只需要简单的设置两个目录，一个是下载目录，一个是保存目录（也可以做硬链接），docker映射的时候不要直接映射根目录，docker会认为是跨盘，就算是跨盘映射二级或下面目录也可以正常使用。</p><h2 id="docker设置"><a href="#docker设置" class="headerlink" title="docker设置"></a>docker设置</h2><p><img src="https://app.bliyun.me:9080/i/2023/11/14/65533bb0a1cdc.jpg" alt="docker映射目录，路径与qbittorrent，emby，chinesesubtitles等连动软件保持一致"></p><p>和qbittorrent的文件映射目录必须完全一样，因为下载完的时候nastools复制&#x2F;转移&#x2F;硬链接等需要发送docker的实际路径。如果qbittorrent的映射路径不一致，会导致复制出错，找不到下载地址，路径不存在等奇怪问题（别问我怎么知道的)。</p><p>up主的media目录为群晖内的电影下载目录，truenas目录是在pt文件夹下nfs映射的目录，实测跨盘跨设备正常运行，做好映射路径就可以了，就是右边的&#x2F;vedio，&#x2F;medio目录，docker只认出右边的路径，不会知道跨盘跨设备。</p><p>目录同步，左边是下载目录，右边是保存目录，有不需要nastool识别的文件夹，例如学习资料，记得把识别重命名关闭掉。</p><p><img src="https://app.bliyun.me:9080/i/2023/11/14/65533bcf3cad8.jpg" alt="目录同步设置"></p><p>基础设置，关闭下载软件监控。</p><p><img src="https://app.bliyun.me:9080/i/2023/11/14/65533bfdc791a.jpg" alt="下载目录"></p><p>下载器-下载目录配置，nastool下载的时候会在qbttorrent推送存储目录，如果这里设置错就会储存在错误地址，切记！</p><p>qbttorrent设置，docker映射的路径和nastool一致</p><p>为了避免nastool同步未完成的文件，请勾上：不完整文件扩展名，默认路径和未完成的文件看个人需要添加。</p><p><img src="https://app.bliyun.me:9080/i/2023/11/14/65533c40d8e8c.jpg" alt="qb设置"></p><p>最好记得右键分类的全部，添加相应的分类名和路径。</p><p>enjoy～～～！</p><p>安装教程一大堆，都是讲一半不讲一半，只好自己摸索，解决问题。nastool记得下载2.91或2.90，别下载新版本，需要bt认证，老版本功能够用了，这些批处理命令不需要更新花巧功能，最后谢谢作者的付出。</p><p>ps:如果遇到困难请给我留言，会尽力解答。</p>]]></content>
      
      
      
        <tags>
            
            <tag> nastool </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>truenas使用nfs传输I/O堵塞踩坑</title>
      <link href="/post/undefined.html"/>
      <url>/post/undefined.html</url>
      
        <content type="html"><![CDATA[<p>宿主系统esxi虚拟了truenas并用nfs协议共享给群晖用来存放电影之类的文件，复制文件的时候经常发现I/O堵塞，<br>具体表现为复制文件时速度慢，而且经常无法响应，用imac的nfs链接truenas也出现同样的情况，<br>最初以为是nfs的权限问题，把权限重新设置一遍后情况如故，<br>最后发现传输文件的时候，truenas的cpu占用非常高，<br>怀疑是分配8个虚拟cpu不够，索性分配40个虚拟cpu，每插槽10个，插槽数4，终于解决了。<br>安装的版本是<b>TrueNAS_SCALE</b>，按照教程安装的时候客户机操作系统系统选择了freebsd，发现esxi报警告，应该选择<font color=red>debain</font>系统，<br>各位记住这个坑：<b>core</b>版本选择freebsd，<b>SCALE</b>版本请选择<font color=red>debain</font>，免得又要重装，郁闷，<br>网上这些教程真的不负责任，写一半不写一半，或者写教程的人本身也不太懂，增加了我们学习成本。</p>]]></content>
      
      
      
        <tags>
            
            <tag> truenas,nfs,群晖 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>openclash订阅链接踩坑记</title>
      <link href="/post/52816.html"/>
      <url>/post/52816.html</url>
      
        <content type="html"><![CDATA[<p>最近的机场老是出问题，于是换了个机场，发现订阅老是失败，具体表现为，可以下载配置文件，配置文件检测通过，但是就是无法，提示内核出错，具体请查看配置文件，查看日志发现读取不了自定义的附加规则导致，把附加的规则去掉后成功订阅，排除了几个小时，真坑。</p>]]></content>
      
      
      
        <tags>
            
            <tag> openclash openwrt </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>解决openwrt内网间歇性无法域名访问nas问题</title>
      <link href="/post/49345.html"/>
      <url>/post/49345.html</url>
      
        <content type="html"><![CDATA[<h1 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h1><p>使用双软路由经常会出现域名访问内网的环路问题，具体情况是域名可以ping通ip但是却间歇性不能访问，遇到这种问题请一一排查原因。</p><h2 id="1-终端ping域名"><a href="#1-终端ping域名" class="headerlink" title="1. 终端ping域名"></a>1. 终端ping域名</h2><h3 id="1-1-如果不能ping通，在软路由继续ping，出现错误ip地址的话是软路由的缓存造成，，重启软路由或负责缓存的软件，"><a href="#1-1-如果不能ping通，在软路由继续ping，出现错误ip地址的话是软路由的缓存造成，，重启软路由或负责缓存的软件，" class="headerlink" title="1.1 如果不能ping通，在软路由继续ping，出现错误ip地址的话是软路由的缓存造成，，重启软路由或负责缓存的软件，"></a>1.1 如果不能ping通，在软路由继续ping，出现错误ip地址的话是软路由的缓存造成，，重启软路由或负责缓存的软件，</h3><p>下面一个个排查，缓存不是越多越好，按照习惯开一个就可以了：</p><ul><li><p>Turbo ACC 网络加速设置，关闭dns缓存。</p></li><li><p>关闭martDNS或MosDNS。</p></li><li><p>清除AdGuard Home缓存。</p></li><li><p>双路由爱快不要设置dns缓存，openwrt缓存dns更专业.</p></li></ul><h3 id="1-2-如果可以ping通"><a href="#1-2-如果可以ping通" class="headerlink" title="1.2 如果可以ping通"></a>1.2 如果可以ping通</h3><p>openwrt-网络，主机名：域名 ip地址：内网转发的ip（通常为群晖ip），设置完清除浏览器缓存或用无痕模式测试即可。</p>]]></content>
      
      
      
        <tags>
            
            <tag> openwrt </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>hexo进阶设置</title>
      <link href="/post/60403.html"/>
      <url>/post/60403.html</url>
      
        <content type="html"><![CDATA[<h3><p>除了学习markdown还有好多东西折腾，今天设置完评论功能，和域名绑定，又要准备部署图传到github了，<br>虽然本地群晖可以搭建图床，可是搭配typora还是不够方便，访问速度也变慢了，<br>反正要翻墙的，索性搭建在github吧hexo当日记使用挺好，<br>很满意hexo但markdown不知要背到什么时候55555～～～～</p></h3>]]></content>
      
      
      
        <tags>
            
            <tag> hexo </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>我的第一篇博客</title>
      <link href="/post/63785.html"/>
      <url>/post/63785.html</url>
      
        <content type="html"><![CDATA[<p>从phpdms，discuz，wordpress到hexo，hexo感觉真不错，借助githu做文件存储，连服务器都不用买了，支持markdown语法，自由的写作方式，无需借助文本编辑器了，唯一缺点是需要学习markdown。<br>  以后再化时间记住markdown语法，无需备案，实名，审核的感觉真好，回到了10几年前建网站的快乐时代。<br>  感谢github大学，各种免费开源的项目，hexo的轻便博客无需数据库php，纯静态页面，愉快的玩耍吧。<p/>  ]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/post/16107.html"/>
      <url>/post/16107.html</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
